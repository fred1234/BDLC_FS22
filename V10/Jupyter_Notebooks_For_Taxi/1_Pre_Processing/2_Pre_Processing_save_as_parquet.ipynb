{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdc91b18-e628-4153-938b-0e78c2ccf796",
   "metadata": {},
   "source": [
    "# Save the raw files as parquet to save space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60c4dea-f391-4aaa-9fa4-3e10b81fff83",
   "metadata": {},
   "source": [
    "We just move the data to parquet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdd8105d-055d-4715-bda0-68ef05051f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237.2 G  237.2 G  /taxi/raw\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -du -s -h /taxi/raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9b2e7ab-251d-45fd-aea7-0c9d299594f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2022-04-26 09:33:03,030 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Convert To Parquet\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5bf4d4-ba82-4012-899c-74fa84496929",
   "metadata": {},
   "source": [
    "### Prepare HDSF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b2699cb-96a9-42b5-875a-7d8e177c96fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: `/taxi/raw_parquet/': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /taxi/raw_parquet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f689029a-d03f-4a23-a232-1bc9790eef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -mkdir /taxi/raw_parquet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6377a2e-fdd3-4466-948d-b7b5314f1864",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls /taxi/raw_parquet/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b5f926-d66a-4a38-9739-e213494b0669",
   "metadata": {},
   "source": [
    "### For every year and month load the csv and save it as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62e7c04c-de54-44d3-b455-0346befe8e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_write(year, month):\n",
    "    spark.read.csv(f\"/taxi/raw/{year}/yellow_tripdata_{year}-{month}.csv\", header=True)\\\n",
    "    .withColumnRenamed(\" pickup_datetime\", \"pickup_datetime\")\\\n",
    "    .withColumnRenamed(\" dropoff_datetime\", \"dropoff_datetime\")\\\n",
    "    .withColumnRenamed(\" passenger_count\", \"passenger_count\")\\\n",
    "    .withColumnRenamed(\" trip_distance\", \"trip_distance\")\\\n",
    "    .withColumnRenamed(\" pickup_longitude\", \"pickup_longitude\")\\\n",
    "    .withColumnRenamed(\" pickup_latitude\", \"pickup_latitude\")\\\n",
    "    .withColumnRenamed(\" rate_code\", \"rate_code\")\\\n",
    "    .withColumnRenamed(\" store_and_fwd_flag\", \"store_and_fwd_flag\")\\\n",
    "    .withColumnRenamed(\" dropoff_longitude\", \"dropoff_longitude\")\\\n",
    "    .withColumnRenamed(\" dropoff_latitude\", \"dropoff_latitude\")\\\n",
    "    .withColumnRenamed(\" payment_type\", \"payment_type\")\\\n",
    "    .withColumnRenamed(\" fare_amount\", \"fare_amount\")\\\n",
    "    .withColumnRenamed(\" surcharge\", \"surcharge\")\\\n",
    "    .withColumnRenamed(\" mta_tax\", \"mta_tax\")\\\n",
    "    .withColumnRenamed(\" tip_amount\", \"tip_amount\")\\\n",
    "    .withColumnRenamed(\" tolls_amount\", \"tolls_amount\")\\\n",
    "    .withColumnRenamed(\" total_amount\", \"total_amount\")\\\n",
    "    .repartition(55).write.parquet(f\"/taxi/raw_parquet/{year}/{month}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6528d60e-0617-4d45-84ae-723bb804c669",
   "metadata": {
    "tags": []
   },
   "source": [
    "### First attempt until 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5119e2b-c131-49b5-ab14-ae65d2c82502",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in [\"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]:\n",
    "    for month in [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]:\n",
    "        !echo processing {year}/{month}\n",
    "        read_and_write(year, month)\n",
    "        ! hdfs dfs -rm -r /taxi/raw/{year}/yellow_tripdata_{year}-{month}.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27660cb-4f59-4bda-88e1-0dd1f2eacb5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Second Try\n",
    "Got the error:\n",
    "- `Column name \" pickup_datetime\" contains invalid character(s). Please use alias to rename it`\n",
    "- `Column name \" dropoff_datetime\" contains invalid character(s). Please use alias to rename it`\n",
    "- `Column name \" passenger_count\" contains invalid character(s). Please use alias to rename it`\n",
    "- `Column name \"  trip_distance\" contains invalid character(s). Please use alias to rename it`\n",
    "- `Column name \"  pickup_longitude\" contains invalid character(s). Please use alias to rename it`\n",
    "- `Column name \"  pickup_latitude\" contains invalid character(s). Please use alias to rename it`\n",
    "- `Column name \"  rate_code\" contains invalid character(s). Please use alias to rename it`\n",
    "- `Column name \"  store_and_fwd_flag\" contains invalid character(s). Please use alias to rename it`\n",
    "\n",
    "etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd5c304-4117-4028-95bf-14f6eb9c816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in [\"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\"]:\n",
    "    for month in [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]:\n",
    "        !echo processing {year}/{month}\n",
    "        read_and_write(year, month)\n",
    "        ! hdfs dfs -rm -r /taxi/raw/{year}/yellow_tripdata_{year}-{month}.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afe8ac2-88ef-42c6-bb56-7a86969a1d20",
   "metadata": {},
   "source": [
    "### Stopping Spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7fe26a4-dc77-4bbd-85c8-7f67b2d39556",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
