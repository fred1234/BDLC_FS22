{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36c9d802-e39e-492d-aa28-f657e58fc5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4856a75c-2bec-4c5c-9167-6a211e96f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection string in SQLAlchemy format\n",
    "%sql hive://hadoop@localhost:10000/gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7bffb80-c319-44c0-af3a-95fec20fc1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://hadoop@localhost:10000/gutenberg\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>line</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>The Project Gutenberg eBook of The Magna Carta</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('The Project Gutenberg eBook of The Magna Carta',)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "Select * from raw_text limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b42ced1-0ff3-4699-a0e1-50331c460b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://hadoop@localhost:10000/gutenberg\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>_c0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>208889834</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(208889834,)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql Select count(*) from raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d2f1bb7-c57f-49f8-bb49-5e800229545a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://hadoop@localhost:10000/gutenberg\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Gutenberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>eBook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>of</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('The',), ('Project',), ('Gutenberg',), ('eBook',), ('of',)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "SELECT explode(split(line,'[ ]')) as word  FROM raw_text LIMIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bf66b22-cb08-448f-8256-e8e12098b400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://hadoop@localhost:10000/gutenberg\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Gutenberg</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('The',), ('Project',), ('Gutenberg',)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "SELECT * FROM (\n",
    "    SELECT explode(split(line,'[ ]')) as word FROM raw_text\n",
    ") word\n",
    "LIMIT 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eabe1f02-f063-45b3-85db-26163d708a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://hadoop@localhost:10000/gutenberg\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>word</th>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td></td>\n",
       "        <td>230055984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>the</td>\n",
       "        <td>85373989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>of</td>\n",
       "        <td>51678554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>and</td>\n",
       "        <td>41021296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>to</td>\n",
       "        <td>35040232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>a</td>\n",
       "        <td>29558866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>in</td>\n",
       "        <td>25832553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>that</td>\n",
       "        <td>13802100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>was</td>\n",
       "        <td>13139989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>is</td>\n",
       "        <td>11569952</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('', 230055984),\n",
       " ('the', 85373989),\n",
       " ('of', 51678554),\n",
       " ('and', 41021296),\n",
       " ('to', 35040232),\n",
       " ('a', 29558866),\n",
       " ('in', 25832553),\n",
       " ('that', 13802100),\n",
       " ('was', 13139989),\n",
       " ('is', 11569952)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT word, count(word) as count FROM (\n",
    "    SELECT explode(split(line,'[ ]')) as word FROM raw_text\n",
    ") word\n",
    "GROUP BY word\n",
    "ORDER BY count DESC\n",
    "LIMIT 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca56a50-4b3a-4d05-b88d-1eabf7953d08",
   "metadata": {},
   "source": [
    "## Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7461f882-f886-42d5-ad96-34428764a8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * hive://hadoop@localhost:10000/gutenberg\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>Explain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>STAGE DEPENDENCIES:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;Stage-1 is a root stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;Stage-2 depends on stages: Stage-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;Stage-0 depends on stages: Stage-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>STAGE PLANS:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;Stage: Stage-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;Map Reduce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Map Operator Tree:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TableScan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;alias: raw_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Statistics: Num rows: 1 Data size: 108234571776 Basic stats: COMPLETE Column stats: NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;GatherStats: false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Select Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expressions: split(line, &#x27;[ ]&#x27;) (type: array&lt;string&gt;)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;outputColumnNames: _col0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Statistics: Num rows: 1 Data size: 108234571776 Basic stats: COMPLETE Column stats: NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;UDTF Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Statistics: Num rows: 1 Data size: 108234571776 Basic stats: COMPLETE Column stats: NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;function name: explode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Group By Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;aggregations: count(col)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keys: col (type: string)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mode: hash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;outputColumnNames: _col0, _col1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Statistics: Num rows: 1 Data size: 108234571776 Basic stats: COMPLETE Column stats: NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Reduce Output Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;key expressions: _col0 (type: string)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;null sort order: a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sort order: +</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Map-reduce partition columns: _col0 (type: string)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Statistics: Num rows: 1 Data size: 108234571776 Basic stats: COMPLETE Column stats: NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tag: -1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;value expressions: _col1 (type: bigint)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;auto parallelism: false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Path -&gt; Alias:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;hdfs://localhost:9000/user/hive/warehouse/gutenberg.db/raw_text [$hdt$_0:raw_text]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Path -&gt; Partition:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;hdfs://localhost:9000/user/hive/warehouse/gutenberg.db/raw_text </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Partition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;base file name: raw_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;input format: org.apache.hadoop.mapred.TextInputFormat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;properties:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bucket_count -1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bucketing_version 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;column.name.delimiter ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;columns line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;columns.comments </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;columns.types string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;file.inputformat org.apache.hadoop.mapred.TextInputFormat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;line.delim </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;location hdfs://localhost:9000/user/hive/warehouse/gutenberg.db/raw_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;name gutenberg.raw_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numFiles 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numRows 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rawDataSize 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serialization.ddl struct raw_text { string line}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serialization.format 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;totalSize 10823456892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;transient_lastDdlTime 1647197774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;input format: org.apache.hadoop.mapred.TextInputFormat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;properties:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bucket_count -1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bucketing_version 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;column.name.delimiter ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;columns line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;columns.comments </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;columns.types string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;file.inputformat org.apache.hadoop.mapred.TextInputFormat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;line.delim </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;location hdfs://localhost:9000/user/hive/warehouse/gutenberg.db/raw_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;name gutenberg.raw_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numFiles 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;numRows 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rawDataSize 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serialization.ddl struct raw_text { string line}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serialization.format 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;totalSize 10823456892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;transient_lastDdlTime 1647197774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;name: gutenberg.raw_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;name: gutenberg.raw_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Truncated Path -&gt; Alias:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;/gutenberg.db/raw_text [$hdt$_0:raw_text]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Needs Tagging: false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Reduce Operator Tree:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Group By Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;aggregations: count(VALUE._col0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keys: KEY._col0 (type: string)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;mode: mergepartial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;outputColumnNames: _col0, _col1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Statistics: Num rows: 1 Data size: 108234571776 Basic stats: COMPLETE Column stats: NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;File Output Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;compressed: false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;GlobalTableId: 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;directory: hdfs://localhost:9000/tmp/hive/hadoop/5a27163c-5d6f-4347-91c9-024aa9531472/hive_2022-03-13_19-33-49_208_4422564591634253528-36/-mr-10004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NumFilesPerFileSink: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;table:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;input format: org.apache.hadoop.mapred.SequenceFileInputFormat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;properties:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;column.name.delimiter ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;columns _col0,_col1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;columns.types string,bigint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;escape.delim \\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TotalFiles: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;GatherStats: false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MultiFileSpray: false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;Stage: Stage-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;Map Reduce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Map Operator Tree:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TableScan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;GatherStats: false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Reduce Output Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;key expressions: _col1 (type: bigint)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;null sort order: z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sort order: -</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Statistics: Num rows: 1 Data size: 108234571776 Basic stats: COMPLETE Column stats: NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tag: -1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;value expressions: _col0 (type: string)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;auto parallelism: false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Execution mode: vectorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Path -&gt; Alias:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;hdfs://localhost:9000/tmp/hive/hadoop/5a27163c-5d6f-4347-91c9-024aa9531472/hive_2022-03-13_19-33-49_208_4422564591634253528-36/-mr-10004 [hdfs://localhost:9000/tmp/hive/hadoop/5a27163c-5d6f-4347-91c9-024aa9531472/hive_2022-03-13_19-33-49_208_4422564591634253528-36/-mr-10004]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Path -&gt; Partition:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;hdfs://localhost:9000/tmp/hive/hadoop/5a27163c-5d6f-4347-91c9-024aa9531472/hive_2022-03-13_19-33-49_208_4422564591634253528-36/-mr-10004 </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Partition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;base file name: -mr-10004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;input format: org.apache.hadoop.mapred.SequenceFileInputFormat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;properties:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;column.name.delimiter ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;columns _col0,_col1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;columns.types string,bigint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;escape.delim \\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;input format: org.apache.hadoop.mapred.SequenceFileInputFormat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;properties:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;column.name.delimiter ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;columns _col0,_col1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;columns.types string,bigint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;escape.delim \\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Truncated Path -&gt; Alias:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;hdfs://localhost:9000/tmp/hive/hadoop/5a27163c-5d6f-4347-91c9-024aa9531472/hive_2022-03-13_19-33-49_208_4422564591634253528-36/-mr-10004 [hdfs://localhost:9000/tmp/hive/hadoop/5a27163c-5d6f-4347-91c9-024aa9531472/hive_2022-03-13_19-33-49_208_4422564591634253528-36/-mr-10004]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Needs Tagging: false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Reduce Operator Tree:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Select Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expressions: VALUE._col0 (type: string), KEY.reducesinkkey0 (type: bigint)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;outputColumnNames: _col0, _col1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Statistics: Num rows: 1 Data size: 108234571776 Basic stats: COMPLETE Column stats: NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;File Output Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;compressed: false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;GlobalTableId: 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;directory: hdfs://localhost:9000/tmp/hive/hadoop/5a27163c-5d6f-4347-91c9-024aa9531472/hive_2022-03-13_19-33-49_208_4422564591634253528-36/-mr-10001/.hive-staging_hive_2022-03-13_19-33-49_208_4422564591634253528-36/-ext-10002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;NumFilesPerFileSink: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Statistics: Num rows: 1 Data size: 108234571776 Basic stats: COMPLETE Column stats: NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Stats Publishing Key Prefix: hdfs://localhost:9000/tmp/hive/hadoop/5a27163c-5d6f-4347-91c9-024aa9531472/hive_2022-03-13_19-33-49_208_4422564591634253528-36/-mr-10001/.hive-staging_hive_2022-03-13_19-33-49_208_4422564591634253528-36/-ext-10002/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;table:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;input format: org.apache.hadoop.mapred.SequenceFileInputFormat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;properties:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;columns _col0,_col1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;columns.types string:bigint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;escape.delim \\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;hive.serialization.extend.additional.nesting.levels true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serialization.escape.crlf true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serialization.format 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;TotalFiles: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;GatherStats: false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;MultiFileSpray: false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;Stage: Stage-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;Fetch Operator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;limit: -1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Processor Tree:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ListSink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td></td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('STAGE DEPENDENCIES:',),\n",
       " ('  Stage-1 is a root stage',),\n",
       " ('  Stage-2 depends on stages: Stage-1',),\n",
       " ('  Stage-0 depends on stages: Stage-2',),\n",
       " ('',),\n",
       " ('STAGE PLANS:',),\n",
       " ('  Stage: Stage-1',),\n",
       " ('    Map Reduce',),\n",
       " ('      Map Operator Tree:',),\n",
       " ('          TableScan',),\n",
       " ('            alias: raw_text',),\n",
       " ('            Statistics: Num rows: 1 Data size: 108234571776 Basic stats: COMPLETE Column stats: NONE',),\n",
       " ('            GatherStats: false',),\n",
       " ('            Select Operator',),\n",
       " (\"              expressions: split(line, '[ ]') (type: array<string>)\",),\n",
       " ('              outputColumnNames: _col0',),\n",
       " ('              Statistics: Num rows: 1 Data size: 108234571776 Basic stats: COMPLETE Column stats: NONE',),\n",
       " ('              UDTF Operator',),\n",
       " ('                Statistics: Num rows: 1 Data size: 108234571776 Basic stats: COMPLETE Column stats: NONE',),\n",
       " ('                function name: explode',),\n",
       " ('                Group By Operator',),\n",
       " ('                  aggregations: count(col)',),\n",
       " ('                  keys: col (type: string)',),\n",
       " ('                  mode: hash',),\n",
       " ('                  outputColumnNames: _col0, _col1',),\n",
       " ('                  Statistics: Num rows: 1 Data size: 108234571776 Basic stats: COMPLETE Column stats: NONE',),\n",
       " ('                  Reduce Output Operator',),\n",
       " ('                    key expressions: _col0 (type: string)',),\n",
       " ('                    null sort order: a',),\n",
       " ('                    sort order: +',),\n",
       " ('                    Map-reduce partition columns: _col0 (type: string)',),\n",
       " ('                    Statistics: Num rows: 1 Data size: 108234571776 Basic stats: COMPLETE Column stats: NONE',),\n",
       " ('                    tag: -1',),\n",
       " ('                    value expressions: _col1 (type: bigint)',),\n",
       " ('                    auto parallelism: false',),\n",
       " ('      Path -> Alias:',),\n",
       " ('        hdfs://localhost:9000/user/hive/warehouse/gutenberg.db/raw_text [$hdt$_0:raw_text]',),\n",
       " ('      Path -> Partition:',),\n",
       " ('        hdfs://localhost:9000/user/hive/warehouse/gutenberg.db/raw_text ',),\n",
       " ('          Partition',),\n",
       " ('            base file name: raw_text',),\n",
       " ('            input format: org.apache.hadoop.mapred.TextInputFormat',),\n",
       " ('            output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',),\n",
       " ('            properties:',),\n",
       " ('              bucket_count -1',),\n",
       " ('              bucketing_version 2',),\n",
       " ('              column.name.delimiter ,',),\n",
       " ('              columns line',),\n",
       " ('              columns.comments ',),\n",
       " ('              columns.types string',),\n",
       " ('              file.inputformat org.apache.hadoop.mapred.TextInputFormat',),\n",
       " ('              file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',),\n",
       " ('              line.delim ',),\n",
       " ('',),\n",
       " ('              location hdfs://localhost:9000/user/hive/warehouse/gutenberg.db/raw_text',),\n",
       " ('              name gutenberg.raw_text',),\n",
       " ('              numFiles 1',),\n",
       " ('              numRows 0',),\n",
       " ('              rawDataSize 0',),\n",
       " ('              serialization.ddl struct raw_text { string line}',),\n",
       " ('              serialization.format 1',),\n",
       " ('              serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',),\n",
       " ('              totalSize 10823456892',),\n",
       " ('              transient_lastDdlTime 1647197774',),\n",
       " ('            serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',),\n",
       " ('          ',),\n",
       " ('              input format: org.apache.hadoop.mapred.TextInputFormat',),\n",
       " ('              output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',),\n",
       " ('              properties:',),\n",
       " ('                bucket_count -1',),\n",
       " ('                bucketing_version 2',),\n",
       " ('                column.name.delimiter ,',),\n",
       " ('                columns line',),\n",
       " ('                columns.comments ',),\n",
       " ('                columns.types string',),\n",
       " ('                file.inputformat org.apache.hadoop.mapred.TextInputFormat',),\n",
       " ('                file.outputformat org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat',),\n",
       " ('                line.delim ',),\n",
       " ('',),\n",
       " ('                location hdfs://localhost:9000/user/hive/warehouse/gutenberg.db/raw_text',),\n",
       " ('                name gutenberg.raw_text',),\n",
       " ('                numFiles 1',),\n",
       " ('                numRows 0',),\n",
       " ('                rawDataSize 0',),\n",
       " ('                serialization.ddl struct raw_text { string line}',),\n",
       " ('                serialization.format 1',),\n",
       " ('                serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',),\n",
       " ('                totalSize 10823456892',),\n",
       " ('                transient_lastDdlTime 1647197774',),\n",
       " ('              serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',),\n",
       " ('              name: gutenberg.raw_text',),\n",
       " ('            name: gutenberg.raw_text',),\n",
       " ('      Truncated Path -> Alias:',),\n",
       " ('        /gutenberg.db/raw_text [$hdt$_0:raw_text]',),\n",
       " ('      Needs Tagging: false',),\n",
       " ('      Reduce Operator Tree:',),\n",
       " ('        Group By Operator',),\n",
       " ('          aggregations: count(VALUE._col0)',),\n",
       " ('          keys: KEY._col0 (type: string)',),\n",
       " ('          mode: mergepartial',),\n",
       " ('          outputColumnNames: _col0, _col1',),\n",
       " ('          Statistics: Num rows: 1 Data size: 108234571776 Basic stats: COMPLETE Column stats: NONE',),\n",
       " ('          File Output Operator',),\n",
       " ('            compressed: false',),\n",
       " ('            GlobalTableId: 0',),\n",
       " ('            directory: hdfs://localhost:9000/tmp/hive/hadoop/5a27163c-5d6f-4347-91c9-024aa9531472/hive_2022-03-13_19-33-49_208_4422564591634253528-36/-mr-10004',),\n",
       " ('            NumFilesPerFileSink: 1',),\n",
       " ('            table:',),\n",
       " ('                input format: org.apache.hadoop.mapred.SequenceFileInputFormat',),\n",
       " ('                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat',),\n",
       " ('                properties:',),\n",
       " ('                  column.name.delimiter ,',),\n",
       " ('                  columns _col0,_col1',),\n",
       " ('                  columns.types string,bigint',),\n",
       " ('                  escape.delim \\\\',),\n",
       " ('                  serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe',),\n",
       " ('                serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe',),\n",
       " ('            TotalFiles: 1',),\n",
       " ('            GatherStats: false',),\n",
       " ('            MultiFileSpray: false',),\n",
       " ('',),\n",
       " ('  Stage: Stage-2',),\n",
       " ('    Map Reduce',),\n",
       " ('      Map Operator Tree:',),\n",
       " ('          TableScan',),\n",
       " ('            GatherStats: false',),\n",
       " ('            Reduce Output Operator',),\n",
       " ('              key expressions: _col1 (type: bigint)',),\n",
       " ('              null sort order: z',),\n",
       " ('              sort order: -',),\n",
       " ('              Statistics: Num rows: 1 Data size: 108234571776 Basic stats: COMPLETE Column stats: NONE',),\n",
       " ('              tag: -1',),\n",
       " ('              value expressions: _col0 (type: string)',),\n",
       " ('              auto parallelism: false',),\n",
       " ('      Execution mode: vectorized',),\n",
       " ('      Path -> Alias:',),\n",
       " ('        hdfs://localhost:9000/tmp/hive/hadoop/5a27163c-5d6f-4347-91c9-024aa9531472/hive_2022-03-13_19-33-49_208_4422564591634253528-36/-mr-10004 [hdfs://localhost:9000/tmp/hive/hadoop/5a27163c-5d6f-4347-91c9-024aa9531472/hive_2022-03-13_19-33-49_208_4422564591634253528-36/-mr-10004]',),\n",
       " ('      Path -> Partition:',),\n",
       " ('        hdfs://localhost:9000/tmp/hive/hadoop/5a27163c-5d6f-4347-91c9-024aa9531472/hive_2022-03-13_19-33-49_208_4422564591634253528-36/-mr-10004 ',),\n",
       " ('          Partition',),\n",
       " ('            base file name: -mr-10004',),\n",
       " ('            input format: org.apache.hadoop.mapred.SequenceFileInputFormat',),\n",
       " ('            output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat',),\n",
       " ('            properties:',),\n",
       " ('              column.name.delimiter ,',),\n",
       " ('              columns _col0,_col1',),\n",
       " ('              columns.types string,bigint',),\n",
       " ('              escape.delim \\\\',),\n",
       " ('              serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe',),\n",
       " ('            serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe',),\n",
       " ('          ',),\n",
       " ('              input format: org.apache.hadoop.mapred.SequenceFileInputFormat',),\n",
       " ('              output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat',),\n",
       " ('              properties:',),\n",
       " ('                column.name.delimiter ,',),\n",
       " ('                columns _col0,_col1',),\n",
       " ('                columns.types string,bigint',),\n",
       " ('                escape.delim \\\\',),\n",
       " ('                serialization.lib org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe',),\n",
       " ('              serde: org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe',),\n",
       " ('      Truncated Path -> Alias:',),\n",
       " ('        hdfs://localhost:9000/tmp/hive/hadoop/5a27163c-5d6f-4347-91c9-024aa9531472/hive_2022-03-13_19-33-49_208_4422564591634253528-36/-mr-10004 [hdfs://localhost:9000/tmp/hive/hadoop/5a27163c-5d6f-4347-91c9-024aa9531472/hive_2022-03-13_19-33-49_208_4422564591634253528-36/-mr-10004]',),\n",
       " ('      Needs Tagging: false',),\n",
       " ('      Reduce Operator Tree:',),\n",
       " ('        Select Operator',),\n",
       " ('          expressions: VALUE._col0 (type: string), KEY.reducesinkkey0 (type: bigint)',),\n",
       " ('          outputColumnNames: _col0, _col1',),\n",
       " ('          Statistics: Num rows: 1 Data size: 108234571776 Basic stats: COMPLETE Column stats: NONE',),\n",
       " ('          File Output Operator',),\n",
       " ('            compressed: false',),\n",
       " ('            GlobalTableId: 0',),\n",
       " ('            directory: hdfs://localhost:9000/tmp/hive/hadoop/5a27163c-5d6f-4347-91c9-024aa9531472/hive_2022-03-13_19-33-49_208_4422564591634253528-36/-mr-10001/.hive-staging_hive_2022-03-13_19-33-49_208_4422564591634253528-36/-ext-10002',),\n",
       " ('            NumFilesPerFileSink: 1',),\n",
       " ('            Statistics: Num rows: 1 Data size: 108234571776 Basic stats: COMPLETE Column stats: NONE',),\n",
       " ('            Stats Publishing Key Prefix: hdfs://localhost:9000/tmp/hive/hadoop/5a27163c-5d6f-4347-91c9-024aa9531472/hive_2022-03-13_19-33-49_208_4422564591634253528-36/-mr-10001/.hive-staging_hive_2022-03-13_19-33-49_208_4422564591634253528-36/-ext-10002/',),\n",
       " ('            table:',),\n",
       " ('                input format: org.apache.hadoop.mapred.SequenceFileInputFormat',),\n",
       " ('                output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat',),\n",
       " ('                properties:',),\n",
       " ('                  columns _col0,_col1',),\n",
       " ('                  columns.types string:bigint',),\n",
       " ('                  escape.delim \\\\',),\n",
       " ('                  hive.serialization.extend.additional.nesting.levels true',),\n",
       " ('                  serialization.escape.crlf true',),\n",
       " ('                  serialization.format 1',),\n",
       " ('                  serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',),\n",
       " ('                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe',),\n",
       " ('            TotalFiles: 1',),\n",
       " ('            GatherStats: false',),\n",
       " ('            MultiFileSpray: false',),\n",
       " ('',),\n",
       " ('  Stage: Stage-0',),\n",
       " ('    Fetch Operator',),\n",
       " ('      limit: -1',),\n",
       " ('      Processor Tree:',),\n",
       " ('        ListSink',),\n",
       " ('',)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "EXPLAIN EXTENDED SELECT word, count(word) as count FROM (\n",
    "    SELECT explode(split(line,'[ ]')) as word FROM raw_text\n",
    ") word\n",
    "GROUP BY word\n",
    "ORDER BY count DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab0c860-8180-4f78-9cea-a747d88eb7ad",
   "metadata": {},
   "source": [
    "## creating table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0150dd-8c3e-4240-b6c1-155ebf432bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE TABLE new_test \n",
    "\n",
    "AS SELECT word, count(word) as count FROM (\n",
    "    SELECT explode(split(line,'[ ]')) as word FROM raw_text\n",
    ") word\n",
    "GROUP BY word\n",
    "ORDER BY count DESC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
